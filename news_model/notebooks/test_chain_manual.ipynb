{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableAssign\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from services import create_chroma_client\n",
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"mistral\")\n",
    "db = Chroma(\n",
    "    client=create_chroma_client(),\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"news\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    model=\"openchat\",\n",
    "    temperature=1,\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_noticias(query: dict) -> Sequence[str]:\n",
    "    import time\n",
    "    import datetime as dt\n",
    "\n",
    "    fecha = query[\"fecha\"].lower()\n",
    "    if fecha == \"ayer\":\n",
    "        fecha_dt = dt.datetime.today() - dt.timedelta(days=1)\n",
    "    else:\n",
    "        fecha_dt = dt.datetime.strptime(fecha, \"%Y-%m-%d\")\n",
    "    fecha_unix = time.mktime(fecha_dt.timetuple())\n",
    "\n",
    "    documents = db.similarity_search(\n",
    "        query[\"tematica\"],\n",
    "        k=5,\n",
    "        filter={\"published\": {\"$gt\": fecha_unix}},\n",
    "    )\n",
    "\n",
    "    if len(documents) > 0:\n",
    "        return \"- \" + \"\\n- \".join([document.page_content for document in documents])\n",
    "    return \"Sin noticias relevantes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_tematica = \"\"\"A partir de la pregunta del usuario, debes extraer la temática \n",
    "a la cual se refiere. Lo que importa es el sujeto, no adjetivos, fechas, etc.\n",
    "\n",
    "Por ejemplo:\n",
    "    - \"qué pasó en Rio de Janeiro ayer?\", la temática es \"Rio de Janeiro\"\n",
    "    - \"qué hiciste ayer en el centro de Rosario?\", la temática es \"centro de Rosario\"\n",
    "    - \"cuantas plantas tiene tu casa?\", la temática es \"plantas de tu casa\"\n",
    "\n",
    "Solo debes responder el nombre de la temática ignorando el resto de la pregunta:\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    "prompt_tematica = ChatPromptTemplate.from_template(template_tematica)\n",
    "\n",
    "chain_tematica = (\n",
    "    RunnableParallel({'input': RunnablePassthrough()})\n",
    "    | prompt_tematica\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.strip())\n",
    ")\n",
    "\n",
    "chain_tematica.name = \"Tematica\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_fecha = \"\"\"A partir de la pregunta del usuario,\n",
    "debes extraer una fecha a la cual hace referencia.\n",
    "Por ejemplo:\n",
    "    - \"qué vas a hacer mañana?\", la fecha es \"mañana\"\n",
    "    - \"qué hiciste ayer?\", la fecha es \"ayer\"\n",
    "    - \"qué hiciste el 1 de noviembre de 1990?\", la fecha es \"1990-11-01\"\n",
    "    \n",
    "En caso de detectar una fecha especifica, devuelvela en formato \"AAAA-MM-DD\".\n",
    "En caso de no estar seguro cuál es la fecha, asume \"Ayer\".\n",
    "\n",
    "Solo debes responder la fecha que detectes:\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    "prompt_fecha = ChatPromptTemplate.from_template(template_fecha)\n",
    "\n",
    "chain_fecha = (\n",
    "    RunnableParallel({'input': RunnablePassthrough()})\n",
    "    | prompt_fecha\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.strip())\n",
    ")\n",
    "\n",
    "chain_fecha.name = \"Fecha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_noticias = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"tematica\": chain_tematica,\n",
    "            \"fecha\": chain_fecha,\n",
    "        }\n",
    "    )\n",
    "    | buscar_noticias\n",
    ")\n",
    "\n",
    "chain_noticias.name = \"Noticias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"A partir de la siguiente pregunta del usuario:\n",
    "\n",
    "{pregunta}\n",
    "\n",
    "Y las siguientes noticias que hablan de la temática del usuario:\n",
    "\n",
    "{contexto}\n",
    "\n",
    "Elabora una respuesta a la pregunta.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"contexto\": chain_noticias,\n",
    "            \"pregunta\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.name = \"Resumen noticias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"Que paso ayer en gran hermano?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ayer en Gran Hermano hubo varias situaciones interesantes que causaron reacciones y discusiones entre los concursantes. El momento en particular que se ha referido el usuario no está claro, pero algunos de los eventos importantes fueron:\n",
      "\n",
      "1. Valeria Mazza y Alejandro Gravier en la tapa de Caras: \"Somos un equipo\". Este encuentro entre dos conocidos de la industria del espectáculo generó mucha expectativa y conversación.\n",
      "\n",
      "2. Beto Casella apuntó contra Luis Majul: lo acusó de copiar \"Bendita TV\". La disputa entre estos dos artistas se volvió viral en las redes sociales, creando un gran impacto público.\n",
      "\n",
      "3. Gran Hermano: Furia dio detalles de su encuentro íntimo con Mauro. Este evento dentro del programa también generó mucha atención y conversación entre los seguidores de la serie.\n",
      "\n",
      "4. Netflix: últimos días para ver un clásico de comedia y baile que supo ser furor. Se trata de una serie muy popular en el servicio de streaming, cuya programación está por finalizar, lo que ha llevado a los fans a conversar sobre sus momentos favoritos y a recordar el impacto que tuvo en la cultura pop.\n",
      "\n",
      "5. Se filtró el verdadero motivo de la separación de Daniel Osvaldo y Daniel Ballester. La información revelada en relación con esta separación de dos celebridades también generó mucha atención y discusión en las redes sociales.\n",
      "\n",
      "En resumen, ayer en Gran Hermano hubo varias noticias interesantes que generaron conversación y expectativa entre los seguidores, pero no se especifica el momento en particular al que se refiere el usuario.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(INPUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
